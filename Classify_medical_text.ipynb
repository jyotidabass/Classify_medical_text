{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classify_medical_text.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOp3mqBb0X29OXt/Bk2yl4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/Classify_medical_text/blob/main/Classify_medical_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MEDICAL TEXT CLASSIFICATION"
      ],
      "metadata": {
        "id": "hxhqAQe6J0LU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iVzj2NzyJ9pS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGjHXzFKFvHl",
        "outputId": "13eb2a2c-7150-47f6-d93d-a43a357f432d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Medical-Text-Classification'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Total 14 (delta 0), reused 0 (delta 0), pack-reused 14\u001b[K\n",
            "Unpacking objects: 100% (14/14), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/prasun1/Medical-Text-Classification.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Loading the dataset in jupyter\n",
        "We have been given train data to train our model and our first step would be to load this data. Following commands are used to load your data."
      ],
      "metadata": {
        "id": "0CNRUMGGKBVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "traindata = pd.read_csv(\"/content/Medical-Text-Classification/Medical.dat\",sep='\\t',header=None)"
      ],
      "metadata": {
        "id": "xIQwLFKgGHjP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Creating Vectors for us as CountVectorizer.\n",
        "Our data is a series of words. We will be using bag of words model to convert text files\n",
        "into numerical feature vectors."
      ],
      "metadata": {
        "id": "YYG8Vms4KUKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "count_vect = CountVectorizer()\n",
        "train_counts = count_vect.fit_transform(traindata[1]) \n",
        "train_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5lTOxTYGWRo",
        "outputId": "25e58fd7-9c1f-4e9e-eb5d-2448c2c254ee"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 179)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Reducing the weightage of common words, so that these common words should not a affect our result."
      ],
      "metadata": {
        "id": "8HKeAJ8TKe_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "train_tfidf = tfidf_transformer.fit_transform(train_counts) \n",
        "train_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIpmh1B3Gg_d",
        "outputId": "5d3c186d-1c09-49a3-9903-dc5f2917531e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 179)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Running Machine Learning Algorithms and train our NB classifier on training data We have used Naive Bayes algorithm for this assignment"
      ],
      "metadata": {
        "id": "XcCejVySKlKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(train_tfidf, traindata[0])"
      ],
      "metadata": {
        "id": "9svgVqXYHBgs"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "        Step 5: Now we will use pipeline from sklearn to build our model"
      ],
      "metadata": {
        "id": "kpsq2e8fKqYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "text_classifier = Pipeline([('vect', CountVectorizer()),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('svc', LinearSVC()),])\n",
        "text_classifier = text_classifier.fit(traindata[1], traindata[0])"
      ],
      "metadata": {
        "id": "e7VVEincHLKb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Now we have build our model and will test this model on our test data and test its efficiency. To load our data we are doing the same steps as done for the load data"
      ],
      "metadata": {
        "id": "mS9ge3d6K_Im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import csv\n",
        "t = open(\"/content/Medical-Text-Classification/Medicaltest.dat\")\n",
        "predicted = text_classifier.predict(t)"
      ],
      "metadata": {
        "id": "xrwcJ5o6H64j"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Predicted the result and uses dataframe and pandas library to build it "
      ],
      "metadata": {
        "id": "BtIpD6fuLENV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame(predicted)"
      ],
      "metadata": {
        "id": "9-1xmgDyIJ8i"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Saved the predicted result in ‘ result_predicted_svcdata.dat’  to compare with the ‘format.dat’"
      ],
      "metadata": {
        "id": "KeDMst6VLIkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_csv('result_predicted_svcdata.dat',index=False,header=None)"
      ],
      "metadata": {
        "id": "jTPD9efNJp3B"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}